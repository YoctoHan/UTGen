#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨ - Stage 1
åŸºäºfew-shotç¤ºä¾‹ç”Ÿæˆç›®æ ‡ç®—å­çš„æµ‹è¯•å‚æ•°
"""

import sys
import os
import json
import csv
import io
from pathlib import Path
from typing import List, Dict, Any, Optional
from utils import (
    get_cpp_files, read_file_content,
    ModelCaller, save_xlsx_content, save_file_content,
    logger, validate_path
)

def load_fewshot_examples(fewshot_file: str) -> str:
    """
    ä»æ–‡ä»¶åŠ è½½few-shotç¤ºä¾‹
    
    Args:
        fewshot_file: few-shotç¤ºä¾‹æ–‡ä»¶è·¯å¾„
    
    Returns:
        str: ç¤ºä¾‹å†…å®¹
    """
    fewshot_path = Path(fewshot_file)
    if not fewshot_path.exists():
        logger.warning(f"Few-shotç¤ºä¾‹æ–‡ä»¶ä¸å­˜åœ¨: {fewshot_file}")
        return ""
    
    try:
        with open(fewshot_path, 'r', encoding='utf-8') as f:
            content = f.read()
        logger.info(f"æˆåŠŸåŠ è½½few-shotç¤ºä¾‹æ–‡ä»¶: {fewshot_file}")
        logger.info(f"ç¤ºä¾‹æ–‡ä»¶å¤§å°: {len(content)} å­—ç¬¦")
        return content
    except Exception as e:
        logger.error(f"è¯»å–few-shotç¤ºä¾‹æ–‡ä»¶å¤±è´¥: {str(e)}")
        return ""


class TestcasePromptGenerator:
    """æµ‹è¯•ç”¨ä¾‹æç¤ºè¯ç”Ÿæˆå™¨"""
    
    def __init__(self, model_caller: ModelCaller, special_reqs_dir: Optional[str] = None):
        self.template = self._load_template()
        self.model_caller = model_caller
        self.special_reqs_dir = Path(special_reqs_dir) if special_reqs_dir else None
    
    def _load_template(self) -> str:
        """åŠ è½½æç¤ºè¯æ¨¡æ¿"""
        return """# ä¸º{operator_name}ç®—å­ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹å‚æ•°

## ä»»åŠ¡ç›®æ ‡
æ ¹æ®{operator_name}ç®—å­çš„æºç å’Œä»¥ä¸‹ç¤ºä¾‹ï¼Œç”Ÿæˆä¸€å¥—å®Œæ•´çš„æµ‹è¯•å‚æ•°ã€‚
è¾“å‡ºæ ¼å¼ä¸ºCSVï¼ŒåŒ…å«æµ‹è¯•ç”¨ä¾‹åç§°å’Œå„ç§å‚æ•°ç»„åˆã€‚

## å‚è€ƒç¤ºä¾‹
{examples_section}

## ç›®æ ‡ç®—å­ç›¸å…³ä¿¡æ¯
### ç®—å­å®Œæ•´æºç 
{source_code_section}

## ç”Ÿæˆè¦æ±‚

### 1. å‚æ•°è®¾è®¡åŸåˆ™
- **è¦†ç›–æ€§**: ç¡®ä¿æµ‹è¯•ç”¨ä¾‹è¦†ç›–ç®—å­çš„æ‰€æœ‰å…³é”®åŠŸèƒ½è·¯å¾„
- **è¾¹ç•Œæµ‹è¯•**: åŒ…å«æœ€å°å€¼ã€æœ€å¤§å€¼ã€è¾¹ç•Œæ¡ä»¶
- **æ€§èƒ½æµ‹è¯•**: åŒ…å«ä¸åŒè§„æ¨¡çš„æ•°æ®æµ‹è¯•
- **å¼‚å¸¸å¤„ç†**: åŒ…å«å¯èƒ½è§¦å‘å¼‚å¸¸çš„å‚æ•°ç»„åˆ

### 2. æµ‹è¯•ç”¨ä¾‹ç±»å‹
è¯·ç”Ÿæˆä»¥ä¸‹ç±»å‹çš„æµ‹è¯•ç”¨ä¾‹ï¼š
- è¯·å°è¯•ç†è§£æºç å’Œç¤ºä¾‹ä¸­çš„ tiling keyï¼Œè¿™æ˜¯ç”Ÿæˆä¼˜è´¨æµ‹è¯•ç”¨ä¾‹çš„å…³é”®
- è¯·å‚è€ƒç¤ºä¾‹ä¸­çš„è¾“å‡ºå½¢å¼ï¼Œå¹¶ç”Ÿæˆç±»ä¼¼çš„æµ‹è¯•ç”¨ä¾‹

### 3. å‚æ•°å‘½åè§„èŒƒ
- ä½¿ç”¨æ¸…æ™°çš„å‚æ•°åç§°ï¼Œä¸æºç ä¸­çš„å˜é‡åä¿æŒä¸€è‡´
- æµ‹è¯•ç”¨ä¾‹åç§°åº”æè¿°æµ‹è¯•ç›®çš„ï¼Œè¯·å‚è€ƒç¤ºä¾‹ä¸­çš„å‘½åæ–¹å¼
- æ•°å€¼å‚æ•°ä½¿ç”¨åˆç†çš„èŒƒå›´å’Œæ­¥é•¿

## ç‰¹æ®Šè¦æ±‚
{special_requirements_section}


### 4. è¾“å‡ºæ ¼å¼
CSVæ ¼å¼ï¼Œç¬¬ä¸€è¡Œä¸ºåˆ—åï¼Œæ ¼å¼ç¤ºä¾‹ï¼š
```csv
test_name,param1,param2,param3,...
basic_small,64,128,256,...
boundary_min,1,1,1,...
```

è¯·ç›´æ¥è¾“å‡ºCSVå†…å®¹ï¼Œè‡³å°‘ç”Ÿæˆ8-10ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼š
"""
    
    def generate(self, operator_name: str, source_paths: List[str], 
                fewshot_content: str, operator_info: Optional[Dict] = None) -> str:
        """
        ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹æç¤ºè¯
        
        Args:
            operator_name: ç®—å­åç§°
            source_paths: æºç è·¯å¾„åˆ—è¡¨
            fewshot_content: few-shotç¤ºä¾‹å†…å®¹
            operator_info: ç®—å­é¢å¤–ä¿¡æ¯
        
        Returns:
            str: ç”Ÿæˆçš„æç¤ºè¯
        """
        
        # ç”Ÿæˆæºç éƒ¨åˆ†
        source_code_section = self._generate_source_section(source_paths)
       
        # æ¶ˆèæ¨¡å‹çš„â€œåˆ†æç®—å­ç‰¹å¾â€è°ƒç”¨
        # ç”Ÿæˆç¤ºä¾‹éƒ¨åˆ†
        examples_section = self._generate_examples_section(fewshot_content)

        # ç”Ÿæˆâ€œç‰¹æ®Šè¦æ±‚â€éƒ¨åˆ†ï¼šæŒ‰ç®—å­åä»ç›®å½•è¯»å–
        special_requirements_section = self._generate_special_requirements(operator_name)
        
        # å¡«å……æ¨¡æ¿
        prompt = self.template.format(
            operator_name=operator_name,
            source_code_section=source_code_section,
            examples_section=examples_section,
            special_requirements_section=special_requirements_section,
        )
        return prompt
    
    def _generate_special_requirements(self, operator_name: str) -> str:
        """æŒ‰ç®—å­åä»ç›®å½•è¯»å–â€œç‰¹æ®Šè¦æ±‚â€æ–‡æœ¬ã€‚

        ä¼˜å…ˆåŒ¹é…åŒåæ–‡ä»¶ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰ï¼Œæ”¯æŒ .md/.txtï¼›
        è‹¥æ‰¾ä¸åˆ°ï¼ŒæŸ¥æ‰¾ DEFAULT.md/DEFAULT.txtï¼›è‹¥ä»æœªæ‰¾åˆ°ï¼Œç»™å‡ºæç¤ºå ä½ã€‚
        """
        if not self.special_reqs_dir:
            return "æœªæä¾›ç‰¹æ®Šè¦æ±‚"

        try:
            if not self.special_reqs_dir.exists():
                return f"æœªæ‰¾åˆ°ç‰¹æ®Šè¦æ±‚ç›®å½•: {self.special_reqs_dir}"

            # ç”Ÿæˆå€™é€‰åï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰
            op_lower = operator_name.lower()

            candidates = []
            for path in self.special_reqs_dir.iterdir():
                if not path.is_file():
                    continue
                stem_lower = path.stem.lower()
                suffix_lower = path.suffix.lower()
                if suffix_lower not in {'.md', '.txt'}:
                    continue
                if stem_lower == op_lower:
                    candidates.append(path)

            # ç²¾ç¡®åŒ¹é…ä¼˜å…ˆ
            target_file = candidates[0] if candidates else None

            # å›é€€åˆ° DEFAULT
            if target_file is None:
                for default_name in ('DEFAULT.md', 'default.md', 'DEFAULT.txt', 'default.txt'):
                    p = self.special_reqs_dir / default_name
                    if p.exists() and p.is_file():
                        target_file = p
                        break

            if target_file is None:
                return "æœªæ‰¾åˆ°ä¸è¯¥ç®—å­åŒ¹é…çš„ç‰¹æ®Šè¦æ±‚"

            content = read_file_content(str(target_file))
            return content if content.strip() else "æœªæ‰¾åˆ°ä¸è¯¥ç®—å­åŒ¹é…çš„ç‰¹æ®Šè¦æ±‚"

        except Exception as exc:
            logger.warning(f"è¯»å–ç‰¹æ®Šè¦æ±‚å¤±è´¥: {exc}")
            return "æœªèƒ½è¯»å–ç‰¹æ®Šè¦æ±‚"

    def _generate_source_section(self, source_paths: List[str]) -> str:
        """ç”Ÿæˆæºç éƒ¨åˆ†"""
        lines = []
        cpp_files = get_cpp_files(source_paths)
        
        if cpp_files:
            logger.info(f"æ”¶é›†åˆ° {len(cpp_files)} ä¸ªæºç æ–‡ä»¶")
            
            for i, file_path in enumerate(cpp_files, 1):
                content = read_file_content(file_path)
                if content.strip():
                    lines.extend([
                        f"#### æºç æ–‡ä»¶ {i}:",
                        "```cpp\n",
                        content,
                        "\n```",
                        ""
                    ])
            
        else:
            lines.append("æœªæ‰¾åˆ°ç›®æ ‡ç®—å­æºç æ–‡ä»¶")
        
        return "\n".join(lines)
    
    def _generate_examples_section(self, fewshot_content: str) -> str:
        """ç”Ÿæˆç¤ºä¾‹éƒ¨åˆ†"""
        if not fewshot_content:
            return "æœªæä¾›few-shotç¤ºä¾‹"
        
        lines = []
        lines.extend([
            "ä»¥ä¸‹æ˜¯ç›¸å…³ç®—å­çš„å®ç°ç¤ºä¾‹ï¼Œè¯·å‚è€ƒå…¶ä»£ç ç»“æ„å’Œå‚æ•°è®¾è®¡æ¨¡å¼ï¼š",
            fewshot_content,
            ""
        ])
        
        return "\n".join(lines)


def parse_csv_response(response: str) -> List[str]:
    """
    è§£ææ¨¡å‹å“åº”ä¸­çš„CSVå†…å®¹
    
    Args:
        response: æ¨¡å‹å“åº”
    
    Returns:
        list: CSVè¡Œåˆ—è¡¨
    """
    lines = response.split('\n')
    csv_lines = []
    in_csv_block = False
    
    for line in lines:
        # æ£€æµ‹CSVä»£ç å—
        if line.strip().startswith('```csv'):
            in_csv_block = True
            continue
        elif line.strip() == '```' and in_csv_block:
            in_csv_block = False
            continue
        elif line.strip().startswith('```'):
            in_csv_block = False
            continue
        
        # æ”¶é›†CSVå†…å®¹
        if in_csv_block and line.strip():  # è¿‡æ»¤ç©ºè¡Œ
            csv_lines.append(line)
        elif not in_csv_block and line.strip() and is_likely_csv_line(line):
            csv_lines.append(line)
    
    # éªŒè¯CSVæ ¼å¼
    if csv_lines:
        validated_lines = validate_csv_format(csv_lines)
        if validated_lines:
            return validated_lines
    
    return csv_lines


def is_likely_csv_line(line: str) -> bool:
    """
    åˆ¤æ–­ä¸€è¡Œæ˜¯å¦å¯èƒ½æ˜¯CSVæ•°æ®
    """
    line = line.strip()
    
    # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Š
    if not line or line.startswith('#') or line.startswith('//'):
        return False
    
    # å°è¯•ç”¨csvæ¨¡å—è§£æ
    try:
        reader = csv.reader(io.StringIO(line))
        fields = next(reader)
        
        # è‡³å°‘è¦æœ‰2ä¸ªå­—æ®µ
        if len(fields) < 2:
            return False
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆå†…å®¹ï¼ˆä¸å…¨æ˜¯ç©ºå­—æ®µï¼‰
        if all(not field.strip() for field in fields):
            return False
            
        return True
        
    except:
        return False


def validate_csv_format(lines: List[str]) -> List[str]:
    """
    éªŒè¯å¹¶è¿”å›æœ‰æ•ˆçš„CSVè¡Œ
    """
    if not lines:
        return []
    
    # å°è¯•è§£æç¬¬ä¸€è¡Œæ¥ç¡®å®šåˆ—æ•°
    try:
        reader = csv.reader(io.StringIO(lines[0]))
        first_row_fields = next(reader)
        expected_columns = len(first_row_fields)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¡¨å¤´
        if not any(char.isdigit() for char in lines[0]):
            logger.info(f"æ£€æµ‹åˆ°CSVè¡¨å¤´ï¼Œå…±{expected_columns}åˆ—")
        
        # éªŒè¯æ‰€æœ‰è¡Œ
        valid_lines = []
        for i, line in enumerate(lines):
            try:
                reader = csv.reader(io.StringIO(line))
                fields = next(reader)
                # è‹¥è¡¨å¤´åŒ…å« op_type ä¸”å½“å‰è¡Œç¬¬äºŒåˆ—åƒå½¢çŠ¶ï¼ˆä»¥æ‹¬å·/ä¸­æ‹¬å·/èŠ±æ‹¬å·å¼€å¤´ï¼‰ï¼Œåˆ™åœ¨ç´¢å¼•1æ’å…¥ç©ºå ä½ï¼Œçº æ­£åˆ—å·¦ç§»
                try:
                    if i > 0 and len(first_row_fields) >= 2 and first_row_fields[1].strip().lower() == 'op_type':
                        if len(fields) >= 2 and fields[1].strip().startswith(('[', '{', '(')):
                            fields.insert(1, '')
                except Exception:
                    pass
                # åˆå¹¶æœªåŠ å¼•å·çš„æ‹¬å·/ä¸­æ‹¬å·/èŠ±æ‹¬å·ä¸­çš„é€—å·ï¼Œé¿å…è¢«è¯¯æ‹†åˆ†ä¸ºå¤šåˆ—
                def _merge_bracket_groups(tokens: List[str]) -> List[str]:
                    merged: List[str] = []
                    buf: List[str] = []
                    open_ch = ''
                    close_ch = ''
                    balance = 0
                    def counts(s: str, ch_open: str, ch_close: str) -> int:
                        return s.count(ch_open) - s.count(ch_close)
                    for t in tokens:
                        st = t.strip()
                        if balance == 0 and st and st[0] in '[{(': 
                            open_ch = st[0]
                            close_ch = { '[': ']', '{': '}', '(': ')' }[open_ch]
                            balance = counts(st, open_ch, close_ch)
                            buf = [t]
                            if balance <= 0:
                                merged.append("".join(buf).strip())
                                buf = []
                                open_ch = close_ch = ''
                                balance = 0
                            continue
                        if balance > 0:
                            buf.append(t)
                            balance += counts(st, open_ch, close_ch)
                            if balance <= 0:
                                merged.append(",".join(buf).strip())
                                buf = []
                                open_ch = close_ch = ''
                                balance = 0
                            continue
                        merged.append(t)
                    if buf:
                        merged.append(",".join(buf).strip())
                    return merged
                fields = _merge_bracket_groups(fields)
                
                # åˆ—æ•°è‡ªé€‚åº”ï¼šå¤šçš„è£å‰ªï¼Œå°‘çš„è¡¥ç©º
                if len(fields) != expected_columns:
                    logger.warning(f"ç¬¬{i+1}è¡Œåˆ—æ•°ä¸åŒ¹é…: æœŸæœ›{expected_columns}åˆ—ï¼Œå®é™…{len(fields)}åˆ—")
                    if len(fields) > expected_columns:
                        fields = fields[:expected_columns]
                    else:
                        fields = fields + [""] * (expected_columns - len(fields))
                    # é‡æ„è¯¥è¡Œ
                    line = ",".join(fields)
                valid_lines.append(line)
                    
            except Exception as e:
                logger.warning(f"ç¬¬{i+1}è¡Œè§£æå¤±è´¥: {e}")
                
        return valid_lines
        
    except Exception as e:
        logger.error(f"CSVæ ¼å¼éªŒè¯å¤±è´¥: {e}")
        return lines


def generate_testcase_params(operator_name: str, source_paths: List[str], 
                            output_file: str, prompt_file: str,
                            fewshot_file: str, api_key: str, 
                            base_url: str, model_name: str) -> bool:
    """
    ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹å‚æ•°çš„ä¸»å‡½æ•°
    
    Args:
        operator_name: ç®—å­åç§°
        source_paths: æºç è·¯å¾„åˆ—è¡¨
        output_file: è¾“å‡ºExcelæ–‡ä»¶è·¯å¾„ï¼ˆXLSXæ ¼å¼ï¼‰
        prompt_file: æç¤ºè¯æ–‡ä»¶è·¯å¾„
        fewshot_file: few-shotç¤ºä¾‹æ–‡ä»¶è·¯å¾„
        api_key: APIå¯†é’¥
        base_url: APIåŸºç¡€URL
        model_name: æ¨¡å‹åç§°
    
    Returns:
        bool: æ˜¯å¦æˆåŠŸ
    """
    logger.info(f"ğŸ¯ å¼€å§‹ä¸º{operator_name}ç®—å­ç”Ÿæˆæµ‹è¯•å‚æ•°")
    logger.info("=" * 50)
    
    # åˆå§‹åŒ–æ¨¡å‹è°ƒç”¨å™¨
    model_caller = ModelCaller(api_key, base_url, model_name, use_cache=True)

    # åŠ è½½few-shotç¤ºä¾‹
    logger.info("ğŸ“š åŠ è½½few-shotç¤ºä¾‹...")
    fewshot_content = load_fewshot_examples(fewshot_file)
    if not fewshot_content:
        logger.warning("æœªèƒ½åŠ è½½few-shotç¤ºä¾‹ï¼Œå°†ä»…åŸºäºæºç ç”Ÿæˆ")
    
    # åˆå§‹åŒ–æç¤ºè¯ç”Ÿæˆå™¨ï¼ˆæ”¯æŒä»ç¯å¢ƒå˜é‡è¯»å–ç‰¹æ®Šè¦æ±‚ç›®å½•ï¼‰
    special_reqs_dir = os.environ.get('SPECIAL_REQS_DIR')
    prompt_generator = TestcasePromptGenerator(model_caller, special_reqs_dir=special_reqs_dir)
    
    # ç”Ÿæˆprompt
    logger.info("ğŸ“ ç”Ÿæˆæµ‹è¯•å‚æ•°ç”Ÿæˆprompt...")
    prompt = prompt_generator.generate(operator_name, source_paths, fewshot_content)
    
    # ä¿å­˜promptåˆ°æ–‡ä»¶
    logger.info("ğŸ’¾ ä¿å­˜promptåˆ°æ–‡ä»¶...")
    if not save_file_content(prompt, prompt_file):
        logger.warning("promptä¿å­˜å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œ...")
    
    logger.info("ğŸ¤– è°ƒç”¨æ¨¡å‹ç”Ÿæˆæµ‹è¯•å‚æ•°...")
    
    system_message = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„C++æµ‹è¯•å·¥ç¨‹å¸ˆï¼Œä¸“é—¨ä¸ºç®—å­è®¾è®¡æµ‹è¯•å‚æ•°ã€‚
è¯·æ ¹æ®æä¾›çš„ç®—å­ä»£ç å’Œç¤ºä¾‹ï¼Œç”Ÿæˆå…¨é¢çš„æµ‹è¯•å‚æ•°é›†ã€‚
ç›´æ¥è¾“å‡ºCSVæ ¼å¼çš„æ•°æ®ï¼Œç¡®ä¿å‚æ•°è¦†ç›–å„ç§æµ‹è¯•åœºæ™¯ã€‚
ç¬¬ä¸€è¡Œå¿…é¡»æ˜¯åˆ—åï¼Œåç»­è¡Œæ˜¯å…·ä½“çš„æµ‹è¯•æ•°æ®ã€‚"""
    
    response = model_caller.call(prompt, system_message, temperature=0.7)
    
    if not response:
        logger.error("æ¨¡å‹è°ƒç”¨å¤±è´¥")
        return False
    
    # è§£æCSVå“åº”
    logger.info("ğŸ“Š è§£æç”Ÿæˆçš„æµ‹è¯•å‚æ•°...")
    csv_lines = parse_csv_response(response)
    
    if not csv_lines:
        logger.error("æœªèƒ½ä»å“åº”ä¸­æå–æœ‰æ•ˆçš„CSVå†…å®¹")
        logger.debug(f"åŸå§‹å“åº”å‰500å­—ç¬¦: {response[:500]}")
        return False
    
    # ä¿å­˜ä¸ºExcelæ–‡ä»¶ï¼ˆXLSXæ ¼å¼ï¼‰
    success = save_xlsx_content(csv_lines, output_file)
    
    if success:
        logger.info("âœ… æµ‹è¯•å‚æ•°ç”Ÿæˆå®Œæˆ!")
        logger.info(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: {output_file}")
        logger.info(f"ğŸ“ Promptæ–‡ä»¶: {prompt_file}")
        
        # æ˜¾ç¤ºé¢„è§ˆ
        if csv_lines:
            logger.info("\nğŸ“‹ ç”Ÿæˆå†…å®¹é¢„è§ˆ:")
            for i, line in enumerate(csv_lines[:5]):
                print(f"  {i+1}: {line}")
            if len(csv_lines) > 5:
                print(f"  ... è¿˜æœ‰ {len(csv_lines) - 5} è¡Œ")
    
    return success


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 9:
        print("ç”¨æ³•: python stage_1.py <ç®—å­åç§°> <è¾“å‡ºExcelæ–‡ä»¶> <Promptæ–‡ä»¶> <Few-shotæ–‡ä»¶> <API_KEY> <BASE_URL> <MODEL_NAME> <æºç è·¯å¾„1> [æºç è·¯å¾„2] ...")
        print()
        print("ç¤ºä¾‹:")
        print("  python stage_1.py AllGatherMatmul test_params.xlsx prompt_testcase.txt \\")
        print("    tiling-examples/fewshot_examples.txt \\")
        print("    your_api_key https://api.com/v1 model-name \\")
        print("    ../cann-ops-adv/src/mc2/all_gather_matmul")
        return
    
    operator_name = sys.argv[1]
    output_file = sys.argv[2]
    prompt_file = sys.argv[3]
    fewshot_file = sys.argv[4]
    api_key = sys.argv[5]
    base_url = sys.argv[6]
    model_name = sys.argv[7]
    source_paths = sys.argv[8:]

    # éªŒè¯few-shotæ–‡ä»¶è·¯å¾„
    if not Path(fewshot_file).exists():
        logger.warning(f"Few-shotæ–‡ä»¶ä¸å­˜åœ¨: {fewshot_file}ï¼Œå°†ä½¿ç”¨é»˜è®¤è·¯å¾„")
        # å°è¯•ä½¿ç”¨é»˜è®¤è·¯å¾„
        default_fewshot = "tiling-examples/fewshot_examples.txt"
        if Path(default_fewshot).exists():
            fewshot_file = default_fewshot
            logger.info(f"ä½¿ç”¨é»˜è®¤few-shotæ–‡ä»¶: {fewshot_file}")

    # éªŒè¯æºç è·¯å¾„
    valid_paths = []
    for path in source_paths:
        validated = validate_path(path, must_exist=True)
        if validated:
            valid_paths.append(str(validated))
        else:
            logger.warning(f"æºç è·¯å¾„ä¸å­˜åœ¨: {path}")
    
    if not valid_paths:
        logger.error("æ²¡æœ‰æœ‰æ•ˆçš„æºç è·¯å¾„")
        sys.exit(1)
    
    # ç”Ÿæˆæµ‹è¯•å‚æ•°
    success = generate_testcase_params(
        operator_name, valid_paths, output_file, prompt_file,
        fewshot_file, api_key, base_url, model_name
    )
    
    if not success:
        logger.error("âŒ æµ‹è¯•å‚æ•°ç”Ÿæˆå¤±è´¥")
        sys.exit(1)


if __name__ == "__main__":
    main()