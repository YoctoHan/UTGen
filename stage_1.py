#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨ - Stage 1
åŸºäºfew-shotç¤ºä¾‹ç”Ÿæˆç›®æ ‡ç®—å­çš„æµ‹è¯•å‚æ•°
"""

import sys
import json
import csv
import io
from pathlib import Path
from typing import List, Dict, Any, Optional
from utils import (
    get_cpp_files, read_file_content,
    ModelCaller, save_xlsx_content, save_file_content,
    logger, validate_path
)


def load_fewshot_examples(fewshot_file: str) -> str:
    """
    ä»æ–‡ä»¶åŠ è½½few-shotç¤ºä¾‹
    
    Args:
        fewshot_file: few-shotç¤ºä¾‹æ–‡ä»¶è·¯å¾„
    
    Returns:
        str: ç¤ºä¾‹å†…å®¹
    """
    fewshot_path = Path(fewshot_file)
    if not fewshot_path.exists():
        logger.warning(f"Few-shotç¤ºä¾‹æ–‡ä»¶ä¸å­˜åœ¨: {fewshot_file}")
        return ""
    
    try:
        with open(fewshot_path, 'r', encoding='utf-8') as f:
            content = f.read()
        logger.info(f"æˆåŠŸåŠ è½½few-shotç¤ºä¾‹æ–‡ä»¶: {fewshot_file}")
        logger.info(f"ç¤ºä¾‹æ–‡ä»¶å¤§å°: {len(content)} å­—ç¬¦")
        return content
    except Exception as e:
        logger.error(f"è¯»å–few-shotç¤ºä¾‹æ–‡ä»¶å¤±è´¥: {str(e)}")
        return ""


class TestcasePromptGenerator:
    """æµ‹è¯•ç”¨ä¾‹æç¤ºè¯ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.template = self._load_template()
    
    def _load_template(self) -> str:
        """åŠ è½½æç¤ºè¯æ¨¡æ¿"""
        return """# ä¸º{operator_name}ç®—å­ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹å‚æ•°

## ä»»åŠ¡ç›®æ ‡
æ ¹æ®{operator_name}ç®—å­çš„æºç å’Œä»¥ä¸‹ç¤ºä¾‹ï¼Œç”Ÿæˆä¸€å¥—å®Œæ•´çš„æµ‹è¯•å‚æ•°ã€‚
è¾“å‡ºæ ¼å¼ä¸ºCSVï¼ŒåŒ…å«æµ‹è¯•ç”¨ä¾‹åç§°å’Œå„ç§å‚æ•°ç»„åˆã€‚

## å‚è€ƒç¤ºä¾‹
{examples_section}

## ç›®æ ‡ç®—å­ç›¸å…³ä¿¡æ¯
### ç®—å­å®Œæ•´æºç 
{source_code_section}

## ç”Ÿæˆè¦æ±‚

### 1. å‚æ•°è®¾è®¡åŸåˆ™
- **è¦†ç›–æ€§**: ç¡®ä¿æµ‹è¯•ç”¨ä¾‹è¦†ç›–ç®—å­çš„æ‰€æœ‰å…³é”®åŠŸèƒ½è·¯å¾„
- **è¾¹ç•Œæµ‹è¯•**: åŒ…å«æœ€å°å€¼ã€æœ€å¤§å€¼ã€è¾¹ç•Œæ¡ä»¶
- **æ€§èƒ½æµ‹è¯•**: åŒ…å«ä¸åŒè§„æ¨¡çš„æ•°æ®æµ‹è¯•
- **å¼‚å¸¸å¤„ç†**: åŒ…å«å¯èƒ½è§¦å‘å¼‚å¸¸çš„å‚æ•°ç»„åˆ

### 2. æµ‹è¯•ç”¨ä¾‹ç±»å‹
è¯·ç”Ÿæˆä»¥ä¸‹ç±»å‹çš„æµ‹è¯•ç”¨ä¾‹ï¼š
- è¯·å°è¯•ç†è§£æºç å’Œç¤ºä¾‹ä¸­çš„ tiling keyï¼Œè¿™æ˜¯ç”Ÿæˆä¼˜è´¨æµ‹è¯•ç”¨ä¾‹çš„å…³é”®
- è¯·å‚è€ƒç¤ºä¾‹ä¸­çš„è¾“å‡ºå½¢å¼ï¼Œå¹¶ç”Ÿæˆç±»ä¼¼çš„æµ‹è¯•ç”¨ä¾‹

### 3. å‚æ•°å‘½åè§„èŒƒ
- ä½¿ç”¨æ¸…æ™°çš„å‚æ•°åç§°ï¼Œä¸æºç ä¸­çš„å˜é‡åä¿æŒä¸€è‡´
- æµ‹è¯•ç”¨ä¾‹åç§°åº”æè¿°æµ‹è¯•ç›®çš„ï¼Œè¯·å‚è€ƒç¤ºä¾‹ä¸­çš„å‘½åæ–¹å¼
- æ•°å€¼å‚æ•°ä½¿ç”¨åˆç†çš„èŒƒå›´å’Œæ­¥é•¿

### 4. è¾“å‡ºæ ¼å¼
CSVæ ¼å¼ï¼Œç¬¬ä¸€è¡Œä¸ºåˆ—åï¼Œæ ¼å¼ç¤ºä¾‹ï¼š
```csv
test_name,param1,param2,param3,...
basic_small,64,128,256,...
boundary_min,1,1,1,...
```

è¯·ç›´æ¥è¾“å‡ºCSVå†…å®¹ï¼Œè‡³å°‘ç”Ÿæˆ8-10ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼š
"""
    
    def generate(self, operator_name: str, source_paths: List[str], 
                fewshot_content: str, operator_info: Optional[Dict] = None) -> str:
        """
        ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹æç¤ºè¯
        
        Args:
            operator_name: ç®—å­åç§°
            source_paths: æºç è·¯å¾„åˆ—è¡¨
            fewshot_content: few-shotç¤ºä¾‹å†…å®¹
            operator_info: ç®—å­é¢å¤–ä¿¡æ¯
        
        Returns:
            str: ç”Ÿæˆçš„æç¤ºè¯
        """
        # åˆ†æç®—å­ç‰¹å¾
        # operator_analysis = self._analyze_operator(operator_name, source_paths)
        
        # ç”Ÿæˆæºç éƒ¨åˆ†
        source_code_section = self._generate_source_section(source_paths)
        
        # ç”Ÿæˆç¤ºä¾‹éƒ¨åˆ†
        examples_section = self._generate_examples_section(fewshot_content)
        
        # ç”Ÿæˆç‰¹æ®Šæ³¨æ„äº‹é¡¹
        # special_notes = self._generate_special_notes(operator_name, operator_info)
        
        # å¡«å……æ¨¡æ¿
        prompt = self.template.format(
            operator_name=operator_name,
            # operator_analysis=operator_analysis,
            source_code_section=source_code_section,
            examples_section=examples_section,
            # special_notes=special_notes
        )
        return prompt
    
    def _analyze_operator(self, operator_name: str, source_paths: List[str]) -> str:
        """åˆ†æç®—å­ç‰¹å¾"""
        analysis = []
        
        # åŸºäºç®—å­åç§°åˆ†æ
        name_lower = operator_name.lower()
        
        if "matmul" in name_lower:
            analysis.append("- çŸ©é˜µä¹˜æ³•è¿ç®—ï¼Œéœ€è¦æµ‹è¯•ä¸åŒçš„çŸ©é˜µç»´åº¦ï¼ˆM, N, Kï¼‰")
        if "allgather" in name_lower:
            analysis.append("- é›†åˆé€šä¿¡æ“ä½œï¼Œéœ€è¦æµ‹è¯•ä¸åŒçš„rankæ•°é‡å’Œæ•°æ®å¤§å°")
        if "reduce" in name_lower:
            analysis.append("- å½’çº¦æ“ä½œï¼Œéœ€è¦æµ‹è¯•ä¸åŒçš„å½’çº¦æ–¹å¼å’Œæ•°æ®åˆ†å¸ƒ")
        if "scatter" in name_lower:
            analysis.append("- åˆ†æ•£æ“ä½œï¼Œéœ€è¦æµ‹è¯•æ•°æ®åˆ†ç‰‡å’Œåˆ†å‘ç­–ç•¥")
        
        # åˆ†ææºç ç‰¹å¾
        cpp_files = get_cpp_files(source_paths)
        if cpp_files:
            for file_path in cpp_files[:3]:  # åªåˆ†æå‰3ä¸ªæ–‡ä»¶
                content = read_file_content(file_path)
                if "template" in content.lower():
                    analysis.append("- ä½¿ç”¨æ¨¡æ¿ï¼Œå¯èƒ½éœ€è¦æµ‹è¯•ä¸åŒçš„æ•°æ®ç±»å‹")
                if "async" in content.lower():
                    analysis.append("- åŒ…å«å¼‚æ­¥æ“ä½œï¼Œéœ€è¦æµ‹è¯•åŒæ­¥å’Œå¼‚æ­¥åœºæ™¯")
                if "stream" in content.lower():
                    analysis.append("- æ¶‰åŠæµæ“ä½œï¼Œéœ€è¦æµ‹è¯•ä¸åŒçš„æµé…ç½®")
        
        if not analysis:
            analysis.append("- æ ‡å‡†ç®—å­å®ç°ï¼Œéœ€è¦å…¨é¢çš„åŠŸèƒ½å’Œæ€§èƒ½æµ‹è¯•")
        
        return "\n".join(analysis)
    
    def _generate_source_section(self, source_paths: List[str]) -> str:
        """ç”Ÿæˆæºç éƒ¨åˆ†"""
        lines = []
        cpp_files = get_cpp_files(source_paths)
        
        if cpp_files:
            logger.info(f"æ”¶é›†åˆ° {len(cpp_files)} ä¸ªæºç æ–‡ä»¶")
            
            for i, file_path in enumerate(cpp_files, 1):
                content = read_file_content(file_path)
                if content.strip():
                    lines.extend([
                        f"#### æºç æ–‡ä»¶ {i}:",
                        "```cpp\n",
                        content,
                        "\n```",
                        ""
                    ])
            
        else:
            lines.append("æœªæ‰¾åˆ°ç›®æ ‡ç®—å­æºç æ–‡ä»¶")
        
        return "\n".join(lines)
    
    def _generate_examples_section(self, fewshot_content: str) -> str:
        """ç”Ÿæˆç¤ºä¾‹éƒ¨åˆ†"""
        if not fewshot_content:
            return "æœªæä¾›few-shotç¤ºä¾‹"
        
        lines = []
        lines.extend([
            "ä»¥ä¸‹æ˜¯ç›¸å…³ç®—å­çš„å®ç°ç¤ºä¾‹ï¼Œè¯·å‚è€ƒå…¶ä»£ç ç»“æ„å’Œå‚æ•°è®¾è®¡æ¨¡å¼ï¼š",
            fewshot_content,
            ""
        ])
        
        return "\n".join(lines)
    
    # def _generate_special_notes(self, operator_name: str, 
    #                            operator_info: Optional[Dict]) -> str:
    #     """ç”Ÿæˆç‰¹æ®Šæ³¨æ„äº‹é¡¹"""
    #     notes = []
        
    #     # åŸºäºç®—å­åç§°çš„ç‰¹æ®Šæ³¨æ„äº‹é¡¹
    #     name_lower = operator_name.lower()
        
    #     if "v2" in name_lower or "v3" in name_lower:
    #         notes.append("- è¿™æ˜¯ç®—å­çš„æ–°ç‰ˆæœ¬ï¼Œå¯èƒ½æœ‰æ€§èƒ½ä¼˜åŒ–æˆ–æ¥å£å˜åŒ–")
        
    #     if "fp16" in name_lower or "bf16" in name_lower:
    #         notes.append("- æ”¯æŒåŠç²¾åº¦æµ®ç‚¹æ•°ï¼Œéœ€è¦æµ‹è¯•ç²¾åº¦ç›¸å…³çš„åœºæ™¯")
        
    #     # ä»operator_infoä¸­æå–é¢å¤–ä¿¡æ¯
    #     if operator_info:
    #         if operator_info.get("hardware_specific"):
    #             notes.append("- ç¡¬ä»¶ç›¸å…³å®ç°ï¼Œéœ€è¦æµ‹è¯•ä¸åŒç¡¬ä»¶é…ç½®")
    #         if operator_info.get("experimental"):
    #             notes.append("- å®éªŒæ€§åŠŸèƒ½ï¼Œéœ€è¦æ›´å…¨é¢çš„è¾¹ç•Œæµ‹è¯•")
        
    #     if not notes:
    #         notes.append("- ç¡®ä¿æµ‹è¯•å‚æ•°ç¬¦åˆç¡¬ä»¶é™åˆ¶å’Œå®é™…ä½¿ç”¨åœºæ™¯")
        
    #     return "\n".join(notes)


def parse_csv_response(response: str) -> List[str]:
    """
    è§£ææ¨¡å‹å“åº”ä¸­çš„CSVå†…å®¹
    
    Args:
        response: æ¨¡å‹å“åº”
    
    Returns:
        list: CSVè¡Œåˆ—è¡¨
    """
    lines = response.split('\n')
    csv_lines = []
    in_csv_block = False
    
    for line in lines:
        # æ£€æµ‹CSVä»£ç å—
        if line.strip().startswith('```csv'):
            in_csv_block = True
            continue
        elif line.strip() == '```' and in_csv_block:
            in_csv_block = False
            continue
        elif line.strip().startswith('```'):
            in_csv_block = False
            continue
        
        # æ”¶é›†CSVå†…å®¹
        if in_csv_block and line.strip():  # è¿‡æ»¤ç©ºè¡Œ
            csv_lines.append(line)
        elif not in_csv_block and line.strip() and is_likely_csv_line(line):
            csv_lines.append(line)
    
    # éªŒè¯CSVæ ¼å¼
    if csv_lines:
        validated_lines = validate_csv_format(csv_lines)
        if validated_lines:
            return validated_lines
    
    return csv_lines


def is_likely_csv_line(line: str) -> bool:
    """
    åˆ¤æ–­ä¸€è¡Œæ˜¯å¦å¯èƒ½æ˜¯CSVæ•°æ®
    """
    line = line.strip()
    
    # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Š
    if not line or line.startswith('#') or line.startswith('//'):
        return False
    
    # å°è¯•ç”¨csvæ¨¡å—è§£æ
    try:
        reader = csv.reader(io.StringIO(line))
        fields = next(reader)
        
        # è‡³å°‘è¦æœ‰2ä¸ªå­—æ®µ
        if len(fields) < 2:
            return False
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆå†…å®¹ï¼ˆä¸å…¨æ˜¯ç©ºå­—æ®µï¼‰
        if all(not field.strip() for field in fields):
            return False
            
        return True
        
    except:
        return False


def validate_csv_format(lines: List[str]) -> List[str]:
    """
    éªŒè¯å¹¶è¿”å›æœ‰æ•ˆçš„CSVè¡Œ
    """
    if not lines:
        return []
    
    # å°è¯•è§£æç¬¬ä¸€è¡Œæ¥ç¡®å®šåˆ—æ•°
    try:
        reader = csv.reader(io.StringIO(lines[0]))
        first_row_fields = next(reader)
        expected_columns = len(first_row_fields)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¡¨å¤´
        if not any(char.isdigit() for char in lines[0]):
            logger.info(f"æ£€æµ‹åˆ°CSVè¡¨å¤´ï¼Œå…±{expected_columns}åˆ—")
        
        # éªŒè¯æ‰€æœ‰è¡Œ
        valid_lines = []
        for i, line in enumerate(lines):
            try:
                reader = csv.reader(io.StringIO(line))
                fields = next(reader)
                
                # ä¸¥æ ¼æ£€æŸ¥åˆ—æ•°ä¸€è‡´æ€§
                if len(fields) == expected_columns:
                    valid_lines.append(line)
                else:
                    logger.warning(f"ç¬¬{i+1}è¡Œåˆ—æ•°ä¸åŒ¹é…: æœŸæœ›{expected_columns}åˆ—ï¼Œå®é™…{len(fields)}åˆ—")
                    
            except Exception as e:
                logger.warning(f"ç¬¬{i+1}è¡Œè§£æå¤±è´¥: {e}")
                
        return valid_lines
        
    except Exception as e:
        logger.error(f"CSVæ ¼å¼éªŒè¯å¤±è´¥: {e}")
        return lines


def generate_testcase_params(operator_name: str, source_paths: List[str], 
                            output_file: str, prompt_file: str,
                            fewshot_file: str, api_key: str, 
                            base_url: str, model_name: str) -> bool:
    """
    ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹å‚æ•°çš„ä¸»å‡½æ•°
    
    Args:
        operator_name: ç®—å­åç§°
        source_paths: æºç è·¯å¾„åˆ—è¡¨
        output_file: è¾“å‡ºExcelæ–‡ä»¶è·¯å¾„ï¼ˆXLSXæ ¼å¼ï¼‰
        prompt_file: æç¤ºè¯æ–‡ä»¶è·¯å¾„
        fewshot_file: few-shotç¤ºä¾‹æ–‡ä»¶è·¯å¾„
        api_key: APIå¯†é’¥
        base_url: APIåŸºç¡€URL
        model_name: æ¨¡å‹åç§°
    
    Returns:
        bool: æ˜¯å¦æˆåŠŸ
    """
    logger.info(f"ğŸ¯ å¼€å§‹ä¸º{operator_name}ç®—å­ç”Ÿæˆæµ‹è¯•å‚æ•°")
    logger.info("=" * 50)
    
    # åŠ è½½few-shotç¤ºä¾‹
    logger.info("ğŸ“š åŠ è½½few-shotç¤ºä¾‹...")
    fewshot_content = load_fewshot_examples(fewshot_file)
    if not fewshot_content:
        logger.warning("æœªèƒ½åŠ è½½few-shotç¤ºä¾‹ï¼Œå°†ä»…åŸºäºæºç ç”Ÿæˆ")
    
    # åˆå§‹åŒ–æç¤ºè¯ç”Ÿæˆå™¨
    prompt_generator = TestcasePromptGenerator()
    
    # ç”Ÿæˆprompt
    logger.info("ğŸ“ ç”Ÿæˆæµ‹è¯•å‚æ•°ç”Ÿæˆprompt...")
    prompt = prompt_generator.generate(operator_name, source_paths, fewshot_content)
    
    # ä¿å­˜promptåˆ°æ–‡ä»¶
    logger.info("ğŸ’¾ ä¿å­˜promptåˆ°æ–‡ä»¶...")
    if not save_file_content(prompt, prompt_file):
        logger.warning("promptä¿å­˜å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œ...")
    
    # åˆå§‹åŒ–æ¨¡å‹è°ƒç”¨å™¨
    logger.info("ğŸ¤– è°ƒç”¨æ¨¡å‹ç”Ÿæˆæµ‹è¯•å‚æ•°...")
    model_caller = ModelCaller(api_key, base_url, model_name, use_cache=True)
    
    system_message = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„C++æµ‹è¯•å·¥ç¨‹å¸ˆï¼Œä¸“é—¨ä¸ºç®—å­è®¾è®¡æµ‹è¯•å‚æ•°ã€‚
è¯·æ ¹æ®æä¾›çš„ç®—å­ä»£ç å’Œç¤ºä¾‹ï¼Œç”Ÿæˆå…¨é¢çš„æµ‹è¯•å‚æ•°é›†ã€‚
ç›´æ¥è¾“å‡ºCSVæ ¼å¼çš„æ•°æ®ï¼Œç¡®ä¿å‚æ•°è¦†ç›–å„ç§æµ‹è¯•åœºæ™¯ã€‚
ç¬¬ä¸€è¡Œå¿…é¡»æ˜¯åˆ—åï¼Œåç»­è¡Œæ˜¯å…·ä½“çš„æµ‹è¯•æ•°æ®ã€‚"""
    
    response = model_caller.call(prompt, system_message, temperature=0.7)
    
    if not response:
        logger.error("æ¨¡å‹è°ƒç”¨å¤±è´¥")
        return False
    
    # è§£æCSVå“åº”
    logger.info("ğŸ“Š è§£æç”Ÿæˆçš„æµ‹è¯•å‚æ•°...")
    csv_lines = parse_csv_response(response)
    
    if not csv_lines:
        logger.error("æœªèƒ½ä»å“åº”ä¸­æå–æœ‰æ•ˆçš„CSVå†…å®¹")
        logger.debug(f"åŸå§‹å“åº”å‰500å­—ç¬¦: {response[:500]}")
        return False
    
    # ä¿å­˜ä¸ºExcelæ–‡ä»¶ï¼ˆXLSXæ ¼å¼ï¼‰
    success = save_xlsx_content(csv_lines, output_file)
    
    if success:
        logger.info("âœ… æµ‹è¯•å‚æ•°ç”Ÿæˆå®Œæˆ!")
        logger.info(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: {output_file}")
        logger.info(f"ğŸ“ Promptæ–‡ä»¶: {prompt_file}")
        
        # æ˜¾ç¤ºé¢„è§ˆ
        if csv_lines:
            logger.info("\nğŸ“‹ ç”Ÿæˆå†…å®¹é¢„è§ˆ:")
            for i, line in enumerate(csv_lines[:5]):
                print(f"  {i+1}: {line}")
            if len(csv_lines) > 5:
                print(f"  ... è¿˜æœ‰ {len(csv_lines) - 5} è¡Œ")
    
    return success


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 9:
        print("ç”¨æ³•: python stage_1.py <ç®—å­åç§°> <è¾“å‡ºExcelæ–‡ä»¶> <Promptæ–‡ä»¶> <Few-shotæ–‡ä»¶> <API_KEY> <BASE_URL> <MODEL_NAME> <æºç è·¯å¾„1> [æºç è·¯å¾„2] ...")
        print()
        print("ç¤ºä¾‹:")
        print("  python stage_1.py AllGatherMatmul test_params.xlsx prompt_testcase.txt \\")
        print("    tiling-examples/fewshot_examples.txt \\")
        print("    your_api_key https://api.com/v1 model-name \\")
        print("    ../cann-ops-adv/src/mc2/all_gather_matmul")
        return
    
    operator_name = sys.argv[1]
    output_file = sys.argv[2]
    prompt_file = sys.argv[3]
    fewshot_file = sys.argv[4]
    api_key = sys.argv[5]
    base_url = sys.argv[6]
    model_name = sys.argv[7]
    source_paths = sys.argv[8:]

    # éªŒè¯few-shotæ–‡ä»¶è·¯å¾„
    if not Path(fewshot_file).exists():
        logger.warning(f"Few-shotæ–‡ä»¶ä¸å­˜åœ¨: {fewshot_file}ï¼Œå°†ä½¿ç”¨é»˜è®¤è·¯å¾„")
        # å°è¯•ä½¿ç”¨é»˜è®¤è·¯å¾„
        default_fewshot = "tiling-examples/fewshot_examples.txt"
        if Path(default_fewshot).exists():
            fewshot_file = default_fewshot
            logger.info(f"ä½¿ç”¨é»˜è®¤few-shotæ–‡ä»¶: {fewshot_file}")

    # éªŒè¯æºç è·¯å¾„
    valid_paths = []
    for path in source_paths:
        validated = validate_path(path, must_exist=True)
        if validated:
            valid_paths.append(str(validated))
        else:
            logger.warning(f"æºç è·¯å¾„ä¸å­˜åœ¨: {path}")
    
    if not valid_paths:
        logger.error("æ²¡æœ‰æœ‰æ•ˆçš„æºç è·¯å¾„")
        sys.exit(1)
    
    # ç”Ÿæˆæµ‹è¯•å‚æ•°
    success = generate_testcase_params(
        operator_name, valid_paths, output_file, prompt_file,
        fewshot_file, api_key, base_url, model_name
    )
    
    if not success:
        logger.error("âŒ æµ‹è¯•å‚æ•°ç”Ÿæˆå¤±è´¥")
        sys.exit(1)


if __name__ == "__main__":
    main()